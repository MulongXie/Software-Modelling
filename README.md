# WebExplorer - Advanced Web Software Analysis

A sophisticated web exploration system that addresses key limitations of traditional web crawlers by implementing **intelligent element prioritization** and **dynamic content handling** with Playwright.

## ğŸ¯ Key Features

### 1. **Smart Element Prioritization** âœ…
- **Navigation elements** (nav buttons, menus) get highest priority
- **Action elements** (buttons, forms) get medium-high priority  
- **Content elements** get lower priority
- **Semantic analysis** based on HTML structure, CSS classes, and text content
- **Global element tracking** across all pages

### 2. **Dynamic Content Handling** âœ…  
- **Playwright integration** for modern SPAs and dynamic sites
- **Smart waiting** for network idle and content loading
- **JavaScript execution** support for React/Vue/Angular apps
- **Login support** with customizable selectors

### 3. **Comprehensive Analysis**
- Clean HTML parsing with noise reduction
- Element classification and prioritization
- Link discovery and exploration
- Performance metrics and load time tracking
- Screenshot capture for visual analysis

### 4. **Extensible Architecture**
- **WebExplorer**: Main orchestrator managing global state
- **WebCrawler**: Playwright-based browser automation
- **HTMLParser**: Content processing and element extraction
- **ElementPrioritizer**: Semantic importance scoring

## ğŸš€ Quick Start

### Installation
```bash
pip install -r requirements.txt
playwright install  # Install browser binaries
```

### Basic Usage
```python
from web_explorer import WebExplorer

# Create explorer instance
explorer = WebExplorer(
    company_name="my_company",
    start_urls=["https://example.com"],
    allowed_domains=["https://example.com"],
    max_state_no=5,
    headless=True
)

# Start exploration
results = explorer.start_exploration()

# Access global elements
nav_elements = explorer.get_global_navigation_elements()
action_elements = explorer.get_global_action_elements()
```

### With Authentication
```python
explorer = WebExplorer(
    company_name="secure_site",
    start_urls=["https://app.example.com/login"],
    allowed_domains=["https://app.example.com"],
    login_credentials={
        'username': 'your_username',
        'password': 'your_password'
    },
    headless=False  # Show browser for debugging
)

results = explorer.start_exploration()
```

### Run Examples
```bash
# Run integrated system demo
python example_integrated.py

# Install Playwright browsers first
playwright install
```

## ğŸ“ New Project Structure

```
â”œâ”€â”€ web_explorer.py          # Main orchestrator class
â”œâ”€â”€ crawler/
â”‚   â””â”€â”€ crawler.py           # Playwright-based web crawler
â”œâ”€â”€ parser/
â”‚   â”œâ”€â”€ page.py              # Page and PageElement classes
â”‚   â”œâ”€â”€ html_parser.py       # HTML cleaning and parsing
â”‚   â””â”€â”€ element_prioritizer.py # Element prioritization logic
â”œâ”€â”€ ref/                     # Reference implementations
â”œâ”€â”€ example_integrated.py    # Integrated system examples
â”œâ”€â”€ requirements.txt         # Dependencies (includes Playwright)
â””â”€â”€ README.md               # This file
```

## ğŸ§© Architecture Overview

```
WebExplorer (Orchestrator)
â”œâ”€â”€ WebCrawler (Playwright-based)
â”‚   â”œâ”€â”€ Browser automation
â”‚   â”œâ”€â”€ Dynamic content handling
â”‚   â”œâ”€â”€ Login support
â”‚   â””â”€â”€ Link extraction
â”œâ”€â”€ HTMLParser (Content Processing)
â”‚   â”œâ”€â”€ HTML cleaning
â”‚   â”œâ”€â”€ Element extraction
â”‚   â””â”€â”€ Link discovery
â”œâ”€â”€ ElementPrioritizer (Intelligence)
â”‚   â”œâ”€â”€ Semantic scoring
â”‚   â”œâ”€â”€ Type classification
â”‚   â””â”€â”€ Priority ranking
â””â”€â”€ Page Objects (Storage)
    â”œâ”€â”€ Individual page data
    â”œâ”€â”€ Element collections
    â””â”€â”€ Metadata
```

## ğŸ¯ Problem-Solution Mapping

### âœ… Problem 1: Element Prioritization 
**Traditional Issue**: All elements treated equally
**Our Solution**: 
- Semantic scoring based on multiple factors
- Global element tracking across pages  
- Explainable prioritization with detailed scoring

### âœ… Problem 2: Dynamic Content Handling
**Traditional Issue**: URL-based crawling misses dynamic content
**Our Solution**:
- Playwright integration for JavaScript execution
- Smart waiting for network idle and content loading
- State change detection without URL changes

## ğŸ”§ Example Output

```
ğŸš€ Starting exploration for my_company
ğŸ“ Output directory: Output/dynamic_crawling/my_company

ğŸ” Exploring URL 1/5: https://example.com
âœ… Successfully analyzed https://example.com
   ğŸ“Š Elements found: 45
   ğŸ”— Links discovered: 12
   â±ï¸ Load time: 1.23s

ğŸ“ˆ Analyzing global patterns across 3 pages...
   ğŸ§­ Global navigation elements: 8
   âš™ï¸ Global settings elements: 3
   ğŸ¯ Global action elements: 15

ğŸ“‹ Exploration Complete!
   ğŸ“„ Pages explored: 3
   ğŸ¯ Total elements: 127
   ğŸ§­ Navigation elements: 8
   âš™ï¸ Settings elements: 3
   ğŸ¯ Action elements: 15
```

## ğŸ“Š Key Advantages Over Traditional Crawlers

| Feature | Traditional Crawlers | WebExplorer |
|---------|---------------------|-------------|
| **Element Priority** | âŒ All equal | âœ… Semantic scoring |
| **Dynamic Content** | âŒ URLs only | âœ… JavaScript execution |
| **Modern SPAs** | âŒ Limited support | âœ… Full support |
| **Global Analysis** | âŒ Page-by-page | âœ… Cross-page patterns |
| **Login Support** | âŒ Manual setup | âœ… Built-in automation |
| **Performance** | âŒ Slow (Selenium) | âœ… Fast (Playwright) |

## ğŸ› ï¸ Advanced Usage

### Custom Element Prioritization
```python
# Access detailed priority explanations
prioritizer = ElementPrioritizer()
explanation = prioritizer.get_priority_explanation(element)
print(f"Score: {explanation['total_score']}")
print(f"Reasoning: {explanation['reasoning']}")
```

### Global Element Analysis
```python
# Get elements that appear across multiple pages
nav_elements = explorer.get_global_navigation_elements()
for elem in nav_elements:
    print(f"Navigation: {elem.text} (Score: {elem.priority_score})")
```

### Custom Crawling Logic
```python
# Access the underlying crawler for custom operations
crawler = explorer.crawler
result = crawler.navigate_to_url("https://custom-page.com")
links = crawler.extract_links()
crawler.take_screenshot("custom_screenshot.png")
```

## ğŸš€ Next Steps & Roadmap

This foundation enables powerful extensions:

1. **Priority Queue Crawling**: Use prioritization for intelligent crawling order
2. **Knowledge Graph Integration**: Export structured data for Q&A systems
3. **ML-Enhanced Classification**: Train models on discovered patterns  
4. **Real-time Monitoring**: Detect site changes and updates
5. **PortalX Integration**: Power advanced interface analysis

## ğŸ¤ Contributing

The modular architecture makes extension straightforward:

1. **Enhance Prioritization**: Modify `ElementPrioritizer.calculate_priority()`
2. **Add Crawler Features**: Extend `WebCrawler` class methods
3. **Custom Analysis**: Create new analysis methods in `WebExplorer`
4. **New Element Types**: Update `HTMLParser._classify_element()`

## ğŸ“„ License

This project is part of the PortalX ecosystem for advanced web interface analysis. 